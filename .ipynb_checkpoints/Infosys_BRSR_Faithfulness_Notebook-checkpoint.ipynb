{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "447ab59f",
   "metadata": {},
   "source": [
    "# Infosys BRSR Principle 6 — Faithfulness Mapper\n",
    "\n",
    "This notebook contains a full reproducible pipeline. It is provided as a sequence of **executable code blocks** (as fenced code) that you can copy into cells and run. This approach avoids environment-dependent issues in this shared environment.\n",
    "\n",
    "Sections:\n",
    "- Installation\n",
    "- Configuration\n",
    "- PDF extraction\n",
    "- Cleaning & chunking\n",
    "- Embeddings (local/OpenAI)\n",
    "- Vector store (FAISS)\n",
    "- Retrieval & RAG\n",
    "- Concept mapping & drift scoring\n",
    "- Visualizations (Sankey & Dashboard)\n",
    "- Pipeline skeleton\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f25c1f1",
   "metadata": {},
   "source": [
    "## 1) Installation\n",
    "\n",
    "run the following in a notebook cell if you need to install dependencies:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cdb6f8-d34f-4b15-b2f1-d7368d403cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python packages (choose based on your preference)\n",
    "pip install PyPDF2 sentence-transformers faiss-cpu plotly pandas matplotlib nbformat\n",
    "# Optional (OpenAI)\n",
    "pip install openai tiktoken chromadb unstructured"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdda2d24",
   "metadata": {},
   "source": [
    "## 2) Configuration\n",
    "\n",
    "Set paths and environment variables. Example (put in a code cell):\n",
    "\n",
    "\n",
    "If you use OpenAI, export your API key in the environment before launching Jupyter:\n",
    "```bash\n",
    "export OPENAI_API_KEY='sk-...'\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f57b9a-4281-4704-9acb-88c10b7f530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SEBI_BRSR_PDF = 'sebi_brsr_guidelines_2021.pdf'\n",
    "INFOSYS_BRSR_PDF = 'infosys_brsr_2022_23.pdf'\n",
    "OUTPUT_DIR = '/mnt/data/infosys_brsr_outputs'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY', '')  # if using OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9005f4",
   "metadata": {},
   "source": [
    "## 3) PDF Extraction (code snippet)\n",
    "\n",
    "Use `PyPDF2` for a simple extraction. Put this into a code cell and run:\n",
    "\n",
    "```python\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_text_pypdf(path, max_pages=None):\n",
    "    reader = PdfReader(path)\n",
    "    texts = []\n",
    "    num_pages = len(reader.pages)\n",
    "    if max_pages:\n",
    "        num_pages = min(num_pages, max_pages)\n",
    "    for i in range(num_pages):\n",
    "        page = reader.pages[i]\n",
    "        texts.append(page.extract_text() or '')\n",
    "    return '\\n'.join(texts)\n",
    "\n",
    "# Example:\n",
    "# sebi_text = extract_text_pypdf(SEBI_BRSR_PDF)\n",
    "# infosys_text = extract_text_pypdf(INFOSYS_BRSR_PDF)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf080a",
   "metadata": {},
   "source": [
    "## 4) Cleaning & Chunking\n",
    "\n",
    "```python\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace('\\x0c', ' ')\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def chunk_text(text, chunk_size=400, overlap=50):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(words):\n",
    "        end = min(start + chunk_size, len(words))\n",
    "        chunk = ' '.join(words[start:end])\n",
    "        chunks.append(chunk)\n",
    "        start += chunk_size - overlap\n",
    "    return chunks\n",
    "\n",
    "# Example:\n",
    "# cleaned = clean_text(infosys_text)\n",
    "# chunks = chunk_text(cleaned, chunk_size=300, overlap=50)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b614d996",
   "metadata": {},
   "source": [
    "## 5) Embeddings (Local and OpenAI examples)\n",
    "\n",
    "### Local (sentence-transformers)\n",
    "\n",
    "```python\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # small & fast\n",
    "def embed_texts_local(texts):\n",
    "    return model.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
    "```\n",
    "\n",
    "### OpenAI (if you prefer)\n",
    "\n",
    "```python\n",
    "import openai\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "def embed_texts_openai(texts, model='text-embedding-3-large'):\n",
    "    # batch for large input\n",
    "    resp = openai.Embedding.create(model=model, input=texts)\n",
    "    vectors = [r['embedding'] for r in resp['data']]\n",
    "    return vectors\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f8bcc8",
   "metadata": {},
   "source": [
    "## 6) Vector Store — FAISS example\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import faiss\n",
    "\n",
    "def build_faiss_index(vectors_np):\n",
    "    dim = vectors_np.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(vectors_np.astype('float32'))\n",
    "    return index\n",
    "\n",
    "# Query example:\n",
    "# D, I = index.search(query_vector.astype('float32'), k)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39ccd2b",
   "metadata": {},
   "source": [
    "## 7) Retrieval & RAG skeleton\n",
    "\n",
    "```python\n",
    "def retrieve_top_k(query, chunks, index, embed_fn, k=5):\n",
    "    q_emb = embed_fn([query])\n",
    "    import numpy as np\n",
    "    q_emb = np.array(q_emb).astype('float32')\n",
    "    D, I = index.search(q_emb, k)\n",
    "    results = [chunks[i] for i in I[0]]\n",
    "    return results\n",
    "\n",
    "# After retrieval, build a prompt that includes only retrieved evidence and ask the LLM to answer using it.\n",
    "# Example prompt outline:\n",
    "# \"You are given the following evidence chunks (labelled). Using ONLY this evidence, answer whether the company's disclosure matches the BRSR requirement X. Quote evidence and give a drift score 0-3. Do not invent facts.\":\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1ebc9a",
   "metadata": {},
   "source": [
    "## 8) Concept Mapping & Drift Scoring\n",
    "\n",
    "Define Principle 6 concepts and a scoring rule. You may start with a naive keyword overlap and then refine.\n",
    "\n",
    "```python\n",
    "BRSR_PRINCIPLE_6_CONCEPTS = [\n",
    "    'Energy consumption','Energy efficiency','Water withdrawal','Water recycling',\n",
    "    'GHG emissions','Scope 1 emissions','Scope 2 emissions','Scope 3 emissions',\n",
    "    'Waste management','Hazardous waste','Biodiversity','Supply chain environmental criteria'\n",
    "]\n",
    "\n",
    "def naive_drift_score(concept, evidence_text):\n",
    "    concept_tokens = set(concept.lower().split())\n",
    "    evidence_tokens = set(evidence_text.lower().split())\n",
    "    overlap = len(concept_tokens & evidence_tokens)\n",
    "    import math\n",
    "    score = 3 - min(3, math.floor(overlap / max(1, len(concept_tokens))))\n",
    "    return score\n",
    "```\n",
    "\n",
    "This function is intentionally simple — use LLM judgment or heuristics for better accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6492fe",
   "metadata": {},
   "source": [
    "## 9) Visualizations — Sankey & Drift Dashboard\n",
    "\n",
    "Example code to produce a Sankey diagram (Plotly) and a simple dashboard (pandas + matplotlib/plotly).\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Example dataframe (replace with real results)\n",
    "df = pd.DataFrame([\n",
    "    {'concept':'Energy consumption','evidence_count':5,'drift':0},\n",
    "    {'concept':'Water withdrawal','evidence_count':3,'drift':1},\n",
    "    {'concept':'GHG emissions','evidence_count':4,'drift':1},\n",
    "    {'concept':'Waste management','evidence_count':4,'drift':0},\n",
    "    {'concept':'Biodiversity','evidence_count':1,'drift':2},\n",
    "])\n",
    "\n",
    "labels = df['concept'].tolist() + ['Infosys Evidence']\n",
    "source = list(range(len(df)))\n",
    "target = [len(df)] * len(df)\n",
    "value = df['evidence_count'].tolist()\n",
    "\n",
    "fig = go.Figure(data=[go.Sankey(node=dict(label=labels), link=dict(source=source, target=target, value=value))])\n",
    "fig.show()\n",
    "# fig.write_html('sankey.html')\n",
    "```\n",
    "\n",
    "For the drift dashboard, color-code drift 0 (green) to 3 (red) using matplotlib or plotly bar charts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60354ec",
   "metadata": {},
   "source": [
    "## 10) Pipeline Skeleton — Run end-to-end\n",
    "\n",
    "Outline (put as code and run when all dependencies are ready):\n",
    "\n",
    "```python\n",
    "# 1. Extract text from SEBI & Infosys PDFs\n",
    "sebi_text = extract_text_pypdf(SEBI_BRSR_PDF)\n",
    "infosys_text = extract_text_pypdf(INFOSYS_BRSR_PDF)\n",
    "\n",
    "# 2. Clean & chunk\n",
    "infosys_chunks = chunk_text(clean_text(infosys_text))\n",
    "\n",
    "# 3. Embeddings (local recommended)\n",
    "infosys_embs = embed_texts_local(infosys_chunks)  # or embed_texts_openai\n",
    "\n",
    "# 4. Build FAISS index\n",
    "import numpy as np\n",
    "index = build_faiss_index(np.array(infosys_embs))\n",
    "\n",
    "# 5. For each concept, retrieve top-k and compute score\n",
    "results = []\n",
    "for concept in BRSR_PRINCIPLE_6_CONCEPTS:\n",
    "    top = retrieve_top_k(concept, infosys_chunks, index, embed_texts_local, k=5)\n",
    "    evidence = ' '.join(top)\n",
    "    score = naive_drift_score(concept, evidence)\n",
    "    results.append({'concept':concept,'score':score,'evidence':' || '.join([t[:300] for t in top])})\n",
    "\n",
    "import pandas as pd\n",
    "pd.DataFrame(results).to_csv('/mnt/data/infosys_brsr_outputs/faithfulness_results.csv', index=False)\n",
    "```\n",
    "\n",
    "After running, generate visualizations and copy top evidence quotes into the Word report.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2063075",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Notes & Recommendations**\n",
    "\n",
    "- The notebook provides a reproducible framework. Human review is essential for final drift scoring and non-hallucination checks.\n",
    "- For best results, create a prompt template that forces the LLM to quote retrieved chunks with page numbers.\n",
    "- Keep all extracted chunk IDs and page references to support the citations required by the assignment.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
